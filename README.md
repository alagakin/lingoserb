# ðŸ‡·ðŸ‡¸ LingoSerb
#### This is the backend part of LingoSerb project.

[Frontend Repo](https://github.com/alagakin/lingoserb-frontend)

The idea of writing something like LingoSerb came to me when I found out that there is few resources which can provide most used Serbian words and use context. Moreover, online translators tend to provide inaccurate information.

One day I tried ChatGPT to get some most used Serbian words and translations, and it did it greate. It provided good use context as well. I thought that this source of language content can be packed in more handy box, something like LingoSerb.

Now LingoSerb provides flashcards for memorization and uses spaced repetition system. Also, it can help with use context of a word. It's quite important when It comes to language learning.

At the moment I'm working on improving content generation accuracy and content filtering system - there is a lot to do.

### To run it follow next steps:

1. Create .evn file and fill in with actual data
    - ```cp .env_example .env```
2. Build project
    - ```docker-compose build```
3. Run project in dev mode
    - ```chmod +x start-dev.sh```
    - ```./start-dev.sh```

In production version (docker-compose.prod.yml) I use Caddy as proxy server with SSL.


## Project components
### OpenAI
Used to generate serbian words, translations and text. It's not always accurate, so it's important to check correctness of translations and words.
### Caddy
Used as a server for production, automatically provides SSL. It proxy requests to gunicorn and serves static files (like images for topics)
### Meilisearch
Search engine for searching through words and translations.
### Redis
Used as cache
### Django
The core component fo the project. The whole API for frontend of LingoSerb is build using **django-rest-framework** and **Django**
### GoogleOAuth
Used to allow user to signup and login with theirs Google account
### Amazon S3
Used to host audio files generated by **gTTS**

## Commands
Almost every piece of content provided by LingoSerb is generated by OpenAI and Text to Speech.
Topics are written manually, you can find json version of them in _app/topics/topics.json
- To put them into db run:

    ```docker-compose run --rm django python manage.py restore_topics```

- In order to generate words for these topics you can run:

    ```docker-compose run --rm django python manage.py populate_topics```
    see more details in _app/ai/management/commands/populate_topics.py

- To generate texts for newly generated words you can run:

    ```docker-compose run --rm django python manage.py generate_texts```
    see more details in _app/ai/management/commands/generate_texts.py

- Now you can make audio files for words and topics:

    ```docker-compose run --rm django python manage.py create_audio``` for words

    and

    ```docker-compose run --rm django python manage.py create_audio --text=1``` for texts

    see more details in _app/words/management/commands/create_audio.py

- To create search index for words just run command:

    ```docker-compose run --rm django python manage.py index --text=1```

- To dump data you can run:

    ```docker-compose run --rm django python manage.py dump```

- Generated db.json can be used to restore database using next command:

    ```docker-compose run --rm django python manage.py loaddata db.json```
